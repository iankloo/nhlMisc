cbind(est = gameIDs[i, 'est'])
)
x[[i]] <- plays
setTxtProgressBar(pb, count)
count <- count + 1
}
dfNew <- do.call('rbind', x)
dfNew <- data.frame(lapply(dfNew, as.character), stringsAsFactors=FALSE)
dfNew
print(paste(errorCount, 'errors'))
}
df <- scrapeSeason(season = '20132014')
i <- 1
season <- '20122013'
season = '20132014'
#---find the game id's
url <- paste('http://live.nhl.com/GameData/SeasonSchedule-', season, '.json', sep = '')
gameInfo <- getURL(url)%>%
fromJSON() %>%
do.call(rbind, .) %>%
apply(., FUN = unlist, 2) %>%
as.data.frame(stringsAsFactors=FALSE)
gameInfo[,'est'] <- as.POSIXct(gameInfo[,'est'], format = '%Y%m%d %T')
#---scrape games before today
startDate <- min(gameInfo$est)
if(max(gameInfo$est) > Sys.time()){
endDate <- Sys.time()
} else{
endDate <- max(gameInfo$est)
}
#gameIDs <- gameInfo[gameInfo$est >= startDate & gameInfo$est < endDate & (gameInfo$a == 'PIT' | gameInfo$h == 'PIT'), c('id','est')]
gameIDs <- gameInfo[gameInfo$est >= startDate & gameInfo$est < endDate, c('id','est')]
x <- vector(mode="list", nrow(gameIDs))
pb <- txtProgressBar(1,nrow(gameIDs), style = 3)
count <- 1
errorCount <- 0
library(RCurl)
library(RJSONIO)
library(dplyr)
#--------scrape a ton of nhl game play by play
setwd('C:/Users/iankl/Desktop/nhlMisc')
scrapeSeason <- function(season){
season <- season
#---find the game id's
url <- paste('http://live.nhl.com/GameData/SeasonSchedule-', season, '.json', sep = '')
gameInfo <- getURL(url)%>%
fromJSON() %>%
do.call(rbind, .) %>%
apply(., FUN = unlist, 2) %>%
as.data.frame(stringsAsFactors=FALSE)
gameInfo[,'est'] <- as.POSIXct(gameInfo[,'est'], format = '%Y%m%d %T')
#---scrape games before today
startDate <- min(gameInfo$est)
if(max(gameInfo$est) > Sys.time()){
endDate <- Sys.time()
} else{
endDate <- max(gameInfo$est)
}
#gameIDs <- gameInfo[gameInfo$est >= startDate & gameInfo$est < endDate & (gameInfo$a == 'PIT' | gameInfo$h == 'PIT'), c('id','est')]
gameIDs <- gameInfo[gameInfo$est >= startDate & gameInfo$est < endDate, c('id','est')]
x <- vector(mode="list", nrow(gameIDs))
pb <- txtProgressBar(1,nrow(gameIDs), style = 3)
count <- 1
errorCount <- 0
for(i in 1:nrow(gameIDs)){
tryCatch({
gameParse <- paste('http://live.nhl.com/GameData/', season, '/', gameIDs[i, 'id'], '/PlayByPlay.json', sep = '') %>%
getURL() %>%
fromJSON()
},error=function(e){
cat("ERROR :",conditionMessage(e), "\n")
errorCount <<- errorCount + 1
})
if(length(gameParse[['data']][['game']][['plays']][['play']]) == 0){
next
}
suppressWarnings(
plays <- gameParse[['data']][['game']][['plays']][['play']] %>%
Reduce(rbind,.) %>%
data.frame() %>%
select(sweater, desc, type, playername, p1name, p2name, p3name, time, period, xcoord, ycoord) %>%
cbind(awayTeam = gameParse[['data']][['game']][['awayteamname']]) %>%
cbind(homeTeam = gameParse[['data']][['game']][['hometeamname']]) %>%
cbind(est = gameIDs[i, 'est'])
)
x[[i]] <- plays
setTxtProgressBar(pb, count)
count <- count + 1
}
dfNew <- do.call('rbind', x)
dfNew <- data.frame(lapply(dfNew, as.character), stringsAsFactors=FALSE)
dfNew
print(paste(errorCount, 'errors'))
}
df <- scrapeSeason(season = '20132014')
library(RCurl)
library(RJSONIO)
library(dplyr)
#--------scrape a ton of nhl game play by play
setwd('C:/Users/iankl/Desktop/nhlMisc')
scrapeSeason <- function(season){
season <- season
#---find the game id's
url <- paste('http://live.nhl.com/GameData/SeasonSchedule-', season, '.json', sep = '')
gameInfo <- getURL(url)%>%
fromJSON() %>%
do.call(rbind, .) %>%
apply(., FUN = unlist, 2) %>%
as.data.frame(stringsAsFactors=FALSE)
gameInfo[,'est'] <- as.POSIXct(gameInfo[,'est'], format = '%Y%m%d %T')
#---scrape games before today
startDate <- min(gameInfo$est)
if(max(gameInfo$est) > Sys.time()){
endDate <- Sys.time()
} else{
endDate <- max(gameInfo$est)
}
#gameIDs <- gameInfo[gameInfo$est >= startDate & gameInfo$est < endDate & (gameInfo$a == 'PIT' | gameInfo$h == 'PIT'), c('id','est')]
gameIDs <- gameInfo[gameInfo$est >= startDate & gameInfo$est < endDate, c('id','est')]
x <- vector(mode="list", nrow(gameIDs))
pb <- txtProgressBar(1,nrow(gameIDs), style = 3)
count <- 1
errorCount <- 0
for(i in 1:nrow(gameIDs)){
tryCatch({
gameParse <- paste('http://live.nhl.com/GameData/', season, '/', gameIDs[i, 'id'], '/PlayByPlay.json', sep = '') %>%
getURL() %>%
fromJSON()
},error=function(e){
cat("ERROR :",conditionMessage(e), "\n")
errorCount <<- errorCount + 1
})
if(length(gameParse[['data']][['game']][['plays']][['play']]) == 0){
next
}
suppressWarnings(
plays <- gameParse[['data']][['game']][['plays']][['play']] %>%
Reduce(rbind,.) %>%
data.frame() %>%
select(sweater, desc, type, playername, p1name, p2name, p3name, time, period, xcoord, ycoord) %>%
cbind(awayTeam = gameParse[['data']][['game']][['awayteamname']]) %>%
cbind(homeTeam = gameParse[['data']][['game']][['hometeamname']]) %>%
cbind(est = gameIDs[i, 'est'])
)
x[[i]] <- plays
setTxtProgressBar(pb, count)
count <- count + 1
}
dfNew <- do.call('rbind', x)
dfNew <- data.frame(lapply(dfNew, as.character), stringsAsFactors=FALSE)
print(paste(errorCount, 'errors'))
dfNew
}
df <- scrapeSeason(season = '20132014')
write.csv(df, 'playByPlay20132014.csv', row.names = FALSE)
df <- scrapeSeason(season = '20122013')
write.csv(df, 'playByPlay20122013.csv', row.names = FALSE)
df <- scrapeSeason(season = '20112012')
write.csv(df, 'playByPlay20112012.csv', row.names = FALSE)
df <- scrapeSeason(season = '20102011')
df <- scrapeSeason(season = '20092010')
plays <- read.csv('playByPlay20162017.csv', stringsAsFactors = FALSE)
test <- read_csv('playByPlay20162017.csv')
library(dplyr)
test <- read_csv('playByPlay20162017.csv')
library(tidyverse)
test <- read_csv('playByPlay20162017.csv')
View(test)
plays <- read_csv('playByPlay20162017.csv')
plays <- read.csv('playByPlay20162017.csv', stringsAsFactors = FALSE)
plays$desc[1]
View(plays)
?select
?filter
goals <- filter(plays, type == 'goal')
goals <- filter(plays, type == 'Goal')
head(goals)
goals[i]
i <- 1
goals[i]
goals[i,]
assists <- goals[0,]
assists <- data.frame(stringsAsFactors = FALSE)
unique(plays$type)
View(plays)
season <- '20162017'
url <- paste('http://live.nhl.com/GameData/SeasonSchedule-', season, '.json', sep = '')
gameInfo <- getURL(url)%>%
fromJSON() %>%
do.call(rbind, .) %>%
apply(., FUN = unlist, 2) %>%
as.data.frame(stringsAsFactors=FALSE)
gameInfo[,'est'] <- as.POSIXct(gameInfo[,'est'], format = '%Y%m%d %T')
#---scrape games before today
startDate <- min(gameInfo$est)
if(max(gameInfo$est) > Sys.time()){
endDate <- Sys.time()
} else{
endDate <- max(gameInfo$est)
}
#gameIDs <- gameInfo[gameInfo$est >= startDate & gameInfo$est < endDate & (gameInfo$a == 'PIT' | gameInfo$h == 'PIT'), c('id','est')]
gameIDs <- gameInfo[gameInfo$est >= startDate & gameInfo$est < endDate, c('id','est')]
x <- vector(mode="list", nrow(gameIDs))
pb <- txtProgressBar(1,nrow(gameIDs), style = 3)
count <- 1
errorCount <- 0
i <- 1
gameParse <- paste('http://live.nhl.com/GameData/', season, '/', gameIDs[i, 'id'], '/PlayByPlay.json', sep = '') %>%
getURL() %>%
fromJSON()
suppressWarnings(
plays <- gameParse[['data']][['game']][['plays']][['play']] %>%
Reduce(rbind,.) %>%
data.frame() %>%
select(sweater, desc, type, playername, p1name, p2name, p3name, time, period, xcoord, ycoord) %>%
cbind(awayTeam = gameParse[['data']][['game']][['awayteamname']]) %>%
cbind(homeTeam = gameParse[['data']][['game']][['hometeamname']]) %>%
cbind(est = gameIDs[i, 'est'])
)
View(plays)
i <-
2
tryCatch({
gameParse <- paste('http://live.nhl.com/GameData/', season, '/', gameIDs[i, 'id'], '/PlayByPlay.json', sep = '') %>%
getURL() %>%
fromJSON()
},error=function(e){
cat("ERROR :",conditionMessage(e), "\n")
errorCount <<- errorCount + 1
})
if(length(gameParse[['data']][['game']][['plays']][['play']]) == 0){
next
}
suppressWarnings(
plays <- gameParse[['data']][['game']][['plays']][['play']] %>%
Reduce(rbind,.) %>%
data.frame() %>%
select(sweater, desc, type, playername, p1name, p2name, p3name, time, period, xcoord, ycoord) %>%
cbind(awayTeam = gameParse[['data']][['game']][['awayteamname']]) %>%
cbind(homeTeam = gameParse[['data']][['game']][['hometeamname']]) %>%
cbind(est = gameIDs[i, 'est'])
)
unique(plays$type)
View(plays)
length(unique(plays$type))
x <- vector(mode="list", nrow(gameIDs))
pb <- txtProgressBar(1,nrow(gameIDs), style = 3)
count <- 1
errorCount <- 0
for(i in 1:nrow(gameIDs)){
tryCatch({
gameParse <- paste('http://live.nhl.com/GameData/', season, '/', gameIDs[i, 'id'], '/PlayByPlay.json', sep = '') %>%
getURL() %>%
fromJSON()
},error=function(e){
cat("ERROR :",conditionMessage(e), "\n")
errorCount <<- errorCount + 1
})
if(length(gameParse[['data']][['game']][['plays']][['play']]) == 0){
next
}
suppressWarnings(
plays <- gameParse[['data']][['game']][['plays']][['play']] %>%
Reduce(rbind,.) %>%
data.frame() %>%
select(sweater, desc, type, playername, p1name, p2name, p3name, time, period, xcoord, ycoord) %>%
cbind(awayTeam = gameParse[['data']][['game']][['awayteamname']]) %>%
cbind(homeTeam = gameParse[['data']][['game']][['hometeamname']]) %>%
cbind(est = gameIDs[i, 'est'])
)
if(length(unique(plays$type)) > 4){
print(i)
break
}
x[[i]] <- plays
setTxtProgressBar(pb, count)
count <- count + 1
}
i
tryCatch({
gameParse <- paste('http://live.nhl.com/GameData/', season, '/', gameIDs[i, 'id'], '/PlayByPlay.json', sep = '') %>%
getURL() %>%
fromJSON()
},error=function(e){
cat("ERROR :",conditionMessage(e), "\n")
errorCount <<- errorCount + 1
})
if(length(gameParse[['data']][['game']][['plays']][['play']]) == 0){
next
}
suppressWarnings(
plays <- gameParse[['data']][['game']][['plays']][['play']] %>%
Reduce(rbind,.) %>%
data.frame() %>%
select(sweater, desc, type, playername, p1name, p2name, p3name, time, period, xcoord, ycoord) %>%
cbind(awayTeam = gameParse[['data']][['game']][['awayteamname']]) %>%
cbind(homeTeam = gameParse[['data']][['game']][['hometeamname']]) %>%
cbind(est = gameIDs[i, 'est'])
)
length(unique(plays$type))
unique(plays$type)
plays[plays$type == -11,]
View(plays)
View(plays)
View(plays)
is.na(plays)
which(is.na(plays))
which(is.na(plays[,]))
plays
tail(plays)
plays
unique(plays$type)
validTypes <- c('Shot', 'Hit', 'Goal', 'Fight', 'Penalty')
i <- 1
i <-2
tryCatch({
gameParse <- paste('http://live.nhl.com/GameData/', season, '/', gameIDs[i, 'id'], '/PlayByPlay.json', sep = '') %>%
getURL() %>%
fromJSON()
},error=function(e){
cat("ERROR :",conditionMessage(e), "\n")
errorCount <<- errorCount + 1
})
if(length(gameParse[['data']][['game']][['plays']][['play']]) == 0){
next
}
suppressWarnings(
plays <- gameParse[['data']][['game']][['plays']][['play']] %>%
Reduce(rbind,.) %>%
data.frame() %>%
select(sweater, desc, type, playername, p1name, p2name, p3name, time, period, xcoord, ycoord) %>%
cbind(awayTeam = gameParse[['data']][['game']][['awayteamname']]) %>%
cbind(homeTeam = gameParse[['data']][['game']][['hometeamname']]) %>%
cbind(est = gameIDs[i, 'est'])
)
unique(plays$type)
validTypes <- c('Shot', 'Hit', 'Goal', 'Fight', 'Penalty')
i <- 1
tryCatch({
gameParse <- paste('http://live.nhl.com/GameData/', season, '/', gameIDs[i, 'id'], '/PlayByPlay.json', sep = '') %>%
getURL() %>%
fromJSON()
},error=function(e){
cat("ERROR :",conditionMessage(e), "\n")
errorCount <<- errorCount + 1
})
if(length(gameParse[['data']][['game']][['plays']][['play']]) == 0){
next
}
suppressWarnings(
plays <- gameParse[['data']][['game']][['plays']][['play']] %>%
Reduce(rbind,.) %>%
data.frame() %>%
select(sweater, desc, type, playername, p1name, p2name, p3name, time, period, xcoord, ycoord) %>%
cbind(awayTeam = gameParse[['data']][['game']][['awayteamname']]) %>%
cbind(homeTeam = gameParse[['data']][['game']][['hometeamname']]) %>%
cbind(est = gameIDs[i, 'est'])
)
test <- plays[plays$type %in% validTypes,]
plays <- plays[plays$type %in% validTypes,]
length(unique(plays$type)) > 4
unique(plays$type)
length(unique(plays$type)) > 5
url <- paste('http://live.nhl.com/GameData/SeasonSchedule-', season, '.json', sep = '')
gameInfo <- getURL(url)%>%
fromJSON() %>%
do.call(rbind, .) %>%
apply(., FUN = unlist, 2) %>%
as.data.frame(stringsAsFactors=FALSE)
gameInfo[,'est'] <- as.POSIXct(gameInfo[,'est'], format = '%Y%m%d %T')
#---scrape games before today
startDate <- min(gameInfo$est)
if(max(gameInfo$est) > Sys.time()){
endDate <- Sys.time()
} else{
endDate <- max(gameInfo$est)
}
#gameIDs <- gameInfo[gameInfo$est >= startDate & gameInfo$est < endDate & (gameInfo$a == 'PIT' | gameInfo$h == 'PIT'), c('id','est')]
gameIDs <- gameInfo[gameInfo$est >= startDate & gameInfo$est < endDate, c('id','est')]
x <- vector(mode="list", nrow(gameIDs))
pb <- txtProgressBar(1,nrow(gameIDs), style = 3)
count <- 1
errorCount <- 0
for(i in 1:nrow(gameIDs)){
tryCatch({
gameParse <- paste('http://live.nhl.com/GameData/', season, '/', gameIDs[i, 'id'], '/PlayByPlay.json', sep = '') %>%
getURL() %>%
fromJSON()
},error=function(e){
cat("ERROR :",conditionMessage(e), "\n")
errorCount <<- errorCount + 1
})
if(length(gameParse[['data']][['game']][['plays']][['play']]) == 0){
next
}
suppressWarnings(
plays <- gameParse[['data']][['game']][['plays']][['play']] %>%
Reduce(rbind,.) %>%
data.frame() %>%
select(sweater, desc, type, playername, p1name, p2name, p3name, time, period, xcoord, ycoord) %>%
cbind(awayTeam = gameParse[['data']][['game']][['awayteamname']]) %>%
cbind(homeTeam = gameParse[['data']][['game']][['hometeamname']]) %>%
cbind(est = gameIDs[i, 'est'])
)
validTypes <- c('Shot', 'Hit', 'Goal', 'Fight', 'Penalty')
plays <- plays[plays$type %in% validTypes,]
if(length(unique(plays$type)) > 5){
print(i)
break
}
x[[i]] <- plays
setTxtProgressBar(pb, count)
count <- count + 1
}
dfNew <- do.call('rbind', x)
dfNew <- data.frame(lapply(dfNew, as.character), stringsAsFactors=FALSE)
unique(dfNew$type)
test <- read.csv('playByPlay20162017.csv')
unique(test$type)
test2 <- test[test$type %in% validTypes,]
test3 <- test[!test$type %in% validTypes,]
View(test3)
unique(dfNew$type)
write.csv(dfNew, 'playByPlay20162017.csv', row.names = FALSE)
setwd('C:/Users/iankl/Desktop/nhlMisc')
scrapeSeason <- function(season){
season <- season
#---find the game id's
url <- paste('http://live.nhl.com/GameData/SeasonSchedule-', season, '.json', sep = '')
gameInfo <- getURL(url)%>%
fromJSON() %>%
do.call(rbind, .) %>%
apply(., FUN = unlist, 2) %>%
as.data.frame(stringsAsFactors=FALSE)
gameInfo[,'est'] <- as.POSIXct(gameInfo[,'est'], format = '%Y%m%d %T')
#---scrape games before today
startDate <- min(gameInfo$est)
if(max(gameInfo$est) > Sys.time()){
endDate <- Sys.time()
} else{
endDate <- max(gameInfo$est)
}
#gameIDs <- gameInfo[gameInfo$est >= startDate & gameInfo$est < endDate & (gameInfo$a == 'PIT' | gameInfo$h == 'PIT'), c('id','est')]
gameIDs <- gameInfo[gameInfo$est >= startDate & gameInfo$est < endDate, c('id','est')]
x <- vector(mode="list", nrow(gameIDs))
pb <- txtProgressBar(1,nrow(gameIDs), style = 3)
count <- 1
errorCount <- 0
for(i in 1:nrow(gameIDs)){
tryCatch({
gameParse <- paste('http://live.nhl.com/GameData/', season, '/', gameIDs[i, 'id'], '/PlayByPlay.json', sep = '') %>%
getURL() %>%
fromJSON()
},error=function(e){
cat("ERROR :",conditionMessage(e), "\n")
errorCount <<- errorCount + 1
})
if(length(gameParse[['data']][['game']][['plays']][['play']]) == 0){
next
}
suppressWarnings(
plays <- gameParse[['data']][['game']][['plays']][['play']] %>%
Reduce(rbind,.) %>%
data.frame() %>%
select(sweater, desc, type, playername, p1name, p2name, p3name, time, period, xcoord, ycoord) %>%
cbind(awayTeam = gameParse[['data']][['game']][['awayteamname']]) %>%
cbind(homeTeam = gameParse[['data']][['game']][['hometeamname']]) %>%
cbind(est = gameIDs[i, 'est'])
)
validTypes <- c('Shot', 'Hit', 'Goal', 'Fight', 'Penalty')
plays <- plays[plays$type %in% validTypes,]
if(length(unique(plays$type)) > 5){
print(i)
break
}
x[[i]] <- plays
setTxtProgressBar(pb, count)
count <- count + 1
}
dfNew <- do.call('rbind', x)
dfNew <- data.frame(lapply(dfNew, as.character), stringsAsFactors=FALSE)
print(paste(errorCount, 'errors'))
dfNew
}
df <- scrapeSeason('20152016')
unique(df$type)
dfOld <- read.csv('playByPlay20152016.csv', stringsAsFactors = FALSE)
unique(dfOld$type)
dfOldFixed <- dfOld[!dfOld$type %in% validTypes,]
dfOldFixed <- dfOld[dfOld$type %in% validTypes,]
df == dfOldFixed
which(df == dfOldFixed)
which(df != dfOldFixed)
dfOldBad <- dfOld[!dfOld$type %in% validTypes,]
View(dfOldBad)
write.csv(df, 'playByPlay20152016.csv', row.names = FALSE)
df <- scrapeSeason('20142015')
write.csv(df, 'playByPlay20142015.csv', row.names = FALSE)
df <- scrapeSeason('20132014')
write.csv(df, 'playByPlay20132014.csv', row.names = FALSE)
df <- read.csv('playByPlay20152016.csv', stringsAsFactors = FALSE)
dfGoals <- df[df$type == 'Goal']
dfGoals <- df[df$type == 'Goal',]
dfGoalsCrosby <- dfGoals[dfGoals$playername == 'Sidney Crosby',]
View(dfGoalsCrosby)
View(df)
dfGoalsCrosby <- dfGoalsCrosby[is.na(dfGoalsCrosby$ycoord) == FALSE,]
View(dfGoalsCrosby)
which(duplicated(dfGoalsCrosby))
dfGoalsCrosby$desc
dfGoalsCrosby <- dfGoals[dfGoals$playername == 'Sidney Crosby',]
View(dfGoalsCrosby)
